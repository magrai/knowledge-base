const local_index = {"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Test Commands Test 2 Project layout Test 3","title":"Home"},{"location":"#home","text":"Test","title":"Home"},{"location":"#commands","text":"Test 2","title":"Commands"},{"location":"#project-layout","text":"Test 3","title":"Project layout"},{"location":"About/","text":"Home Test Commands Test 2 Project layout Test 3","title":"Home"},{"location":"About/#home","text":"Test","title":"Home"},{"location":"About/#commands","text":"Test 2","title":"Commands"},{"location":"About/#project-layout","text":"Test 3","title":"Project layout"},{"location":"ML/Concepts/imbalanced-classification/","text":"Imbalanced classification Foundation Definition Classification is the task of predicting a class label for a given observation Imbalanced classification is an example of a classification problem where the distribution of observations across the known classes is not equal (skewed class distribution) Other names \"Imbalanced classification\" problems can also be described as follows: Rare event prediction Extreme event prediction Severe class imbalance Comparison to unbalanced classification Unbalanced classification refers to a class distribution that was balanced and is now no longer balanced Imbalanced classification refers to a class distribution that is inherently not balanced Types of classes The non-equal classes can be differentiated as follows: Majority class The class (or classes) that has more observations Minority class The class that has has less observations When working with an imbalanced classification problem, the monitory class is typically of the most interest Severity of imbalance The imbalance of a problem is defined by the distribution of classes in a specific training dataset (not the test dataset) Describing the severity of imbalance Severity of imbalance in terms of ratio It is common to describe the imbalance of classes in a dataset in terms of ratio Example: An imbalanced binary classification problem with an imbalance of 1:100 means that for every one example in one class, there are 100 examples in the other class Severity of imbalance as percentage Another way to describe the imbalance of classes in a dataset is to summarize the class distribution as percentages of the training dataset Example: An imbalanced multiclass classification problem may have 80 % examples in the first class, 18 % in the second class, and 2 % in the third class Types of severity The severity of imbalance can be differentiated as follows: Slight imbalance Distributions of observations is uneven by a small amount in the training dataset (e.g. 4:6) Severe imbalance Distributions of observations is uneven by a large amount in the training dataset (e.g. 1:100 or more) Causes of class imbalance The imbalance of the class distribution may have many causes There are perhaps two main groups of causes: Data sampling Properties of the problem domain Data sampling It is possible that the imbalance was caused by the way the examples were collected or sampled from the problem domain This might involve: Biased sampling Measurement errors Biased sampling Measurement errors The processes or systems from which observations were collected may have been damaged The wrong class labels might have been applied to many observations Solution * The imbalance can be corrected by improved sampling methods and/or correcting the measurement error Properties of the problem domain The natural occurrence or presence of one class may dominate other classes This may be because the process that generates observations on one class is more expensive in time, cost, computation, or other resources Solution * It is often infeasible or intractable to simply collect more samples from the domain * Instead, a model is required to learn the difference between the classes Examples Most of the following examples are likely binary classification problems Many of the domains are described as detection , highlighting the desire to discover the monitory class amongst the abundant examples of the majority class Examples Fraud detection Claim prediction Default prediction Churn prediction Spam detection Anomaly detection Outlier detection Intrusion detection Conversion prediction Appraisal Most of the contemporary works in class imbalance concentrate on imbalance ratios ranging from 1:4 up to 1:100 In real-life applications such as fraud detection or cheminformatics we may deal with problems with imbalance ratios ranging from 1:1000 up to 1:5000 A slight imbalance is often not a concern, and the problem can often be treated like a normal classification problem A severe imbalance can be challenging to model and may require the use of specialized techniques Imbalance classification is not solved It remains an open problem generally, and practically must be identified and addressed specifically for each training dataset This is true even in the face of big data, deep learning, and competition-winning models (xgboost) Challenges Foundational challenges of imbalanced classification Skewed class distribution Most ML algorithms for classification are designed and demonstrated on problems that assume an equal distribution of classes In imbalanced classification problems, the minority class is harder to predict because: There are few observations of this class and The abundance of observations from the majority class can swamp the minority class Hence, it is more challenging for a model to learn the characteristics of observations from the minority class, and to differentiate observations from this class from the majority class A na\u00efve application of a model may focus on learning the characteristics of the abundant observations only, neglecting the observations from the minority class Most ML algorithms will perform poorly and require modification to avoid simply predicting the majority class in all cases Additionally, metrics like classification accuracy lose their meaning and alternate methods for evaluating predictions on imbalanced examples are required, like ROC area under the curve Cost sensitivity It is common for the majority class to represent a normal case in the domain, whereas the minority class to represent an abnormal case (such as a fault, fraud, outlier, anomaly, disease state, ...) As such, the interpretation of misclassification errors may differ across the classes Example: Misclassifying an example for the majority class as an example from the minority class (a so-called false positive) is often not desired, but less critical than classifying an example from the minority class as belonging to the majority class (a so-called false negative) This is referred to as cost sensitivity of misclassification errors Compounding effects There are other characteristics of the classification problem that, when combined with these foundational challenges, compound their effect and magnify the difficulty of imbalanced classification problems Dataset size Label noise Data distribution Effect of dataset size Dataset size refers to the number of observations collected from the problem domain to fit and evaluate a model Typically, more data is better as it provides more coverage of the domain, perhaps to a point of diminishing returns Specifically, more data provides better representation of combinations and variance of features in the feature space and their mapping to class labels From this, a model can better learn and generalize a class boundary to discriminate new observations in the future If the ratio of examples in the majority class to minority class is somewhat fixed, then we would expect that we would have more examples in the minority class as the size of the dataset is scaled up This is good if we can collect more examples It is a problem typically because data is hard or expensive to collect and we often collect and work with a lot less data than we might prefer As such, this can dramatically impact our ability to gain a large enough or representative sample of examples from the minority class Effect of label noise Effect of data distribution","title":"Imbalanced classification"},{"location":"ML/Concepts/imbalanced-classification/#imbalanced-classification","text":"","title":"Imbalanced classification"},{"location":"ML/Concepts/imbalanced-classification/#foundation","text":"","title":"Foundation"},{"location":"ML/Concepts/imbalanced-classification/#definition","text":"Classification is the task of predicting a class label for a given observation Imbalanced classification is an example of a classification problem where the distribution of observations across the known classes is not equal (skewed class distribution)","title":"Definition"},{"location":"ML/Concepts/imbalanced-classification/#other-names","text":"\"Imbalanced classification\" problems can also be described as follows: Rare event prediction Extreme event prediction Severe class imbalance","title":"Other names"},{"location":"ML/Concepts/imbalanced-classification/#comparison-to-unbalanced-classification","text":"Unbalanced classification refers to a class distribution that was balanced and is now no longer balanced Imbalanced classification refers to a class distribution that is inherently not balanced","title":"Comparison to unbalanced classification"},{"location":"ML/Concepts/imbalanced-classification/#types-of-classes","text":"The non-equal classes can be differentiated as follows: Majority class The class (or classes) that has more observations Minority class The class that has has less observations When working with an imbalanced classification problem, the monitory class is typically of the most interest","title":"Types of classes"},{"location":"ML/Concepts/imbalanced-classification/#severity-of-imbalance","text":"The imbalance of a problem is defined by the distribution of classes in a specific training dataset (not the test dataset)","title":"Severity of imbalance"},{"location":"ML/Concepts/imbalanced-classification/#describing-the-severity-of-imbalance","text":"Severity of imbalance in terms of ratio It is common to describe the imbalance of classes in a dataset in terms of ratio Example: An imbalanced binary classification problem with an imbalance of 1:100 means that for every one example in one class, there are 100 examples in the other class Severity of imbalance as percentage Another way to describe the imbalance of classes in a dataset is to summarize the class distribution as percentages of the training dataset Example: An imbalanced multiclass classification problem may have 80 % examples in the first class, 18 % in the second class, and 2 % in the third class","title":"Describing the severity of imbalance"},{"location":"ML/Concepts/imbalanced-classification/#types-of-severity","text":"The severity of imbalance can be differentiated as follows: Slight imbalance Distributions of observations is uneven by a small amount in the training dataset (e.g. 4:6) Severe imbalance Distributions of observations is uneven by a large amount in the training dataset (e.g. 1:100 or more)","title":"Types of severity"},{"location":"ML/Concepts/imbalanced-classification/#causes-of-class-imbalance","text":"The imbalance of the class distribution may have many causes There are perhaps two main groups of causes: Data sampling Properties of the problem domain","title":"Causes of class imbalance"},{"location":"ML/Concepts/imbalanced-classification/#data-sampling","text":"It is possible that the imbalance was caused by the way the examples were collected or sampled from the problem domain This might involve: Biased sampling Measurement errors","title":"Data sampling"},{"location":"ML/Concepts/imbalanced-classification/#biased-sampling","text":"","title":"Biased sampling"},{"location":"ML/Concepts/imbalanced-classification/#measurement-errors","text":"The processes or systems from which observations were collected may have been damaged The wrong class labels might have been applied to many observations Solution * The imbalance can be corrected by improved sampling methods and/or correcting the measurement error","title":"Measurement errors"},{"location":"ML/Concepts/imbalanced-classification/#properties-of-the-problem-domain","text":"The natural occurrence or presence of one class may dominate other classes This may be because the process that generates observations on one class is more expensive in time, cost, computation, or other resources Solution * It is often infeasible or intractable to simply collect more samples from the domain * Instead, a model is required to learn the difference between the classes","title":"Properties of the problem domain"},{"location":"ML/Concepts/imbalanced-classification/#examples","text":"Most of the following examples are likely binary classification problems Many of the domains are described as detection , highlighting the desire to discover the monitory class amongst the abundant examples of the majority class Examples Fraud detection Claim prediction Default prediction Churn prediction Spam detection Anomaly detection Outlier detection Intrusion detection Conversion prediction","title":"Examples"},{"location":"ML/Concepts/imbalanced-classification/#appraisal","text":"Most of the contemporary works in class imbalance concentrate on imbalance ratios ranging from 1:4 up to 1:100 In real-life applications such as fraud detection or cheminformatics we may deal with problems with imbalance ratios ranging from 1:1000 up to 1:5000 A slight imbalance is often not a concern, and the problem can often be treated like a normal classification problem A severe imbalance can be challenging to model and may require the use of specialized techniques Imbalance classification is not solved It remains an open problem generally, and practically must be identified and addressed specifically for each training dataset This is true even in the face of big data, deep learning, and competition-winning models (xgboost)","title":"Appraisal"},{"location":"ML/Concepts/imbalanced-classification/#challenges","text":"","title":"Challenges"},{"location":"ML/Concepts/imbalanced-classification/#foundational-challenges-of-imbalanced-classification","text":"","title":"Foundational challenges of imbalanced classification"},{"location":"ML/Concepts/imbalanced-classification/#skewed-class-distribution","text":"Most ML algorithms for classification are designed and demonstrated on problems that assume an equal distribution of classes In imbalanced classification problems, the minority class is harder to predict because: There are few observations of this class and The abundance of observations from the majority class can swamp the minority class Hence, it is more challenging for a model to learn the characteristics of observations from the minority class, and to differentiate observations from this class from the majority class A na\u00efve application of a model may focus on learning the characteristics of the abundant observations only, neglecting the observations from the minority class Most ML algorithms will perform poorly and require modification to avoid simply predicting the majority class in all cases Additionally, metrics like classification accuracy lose their meaning and alternate methods for evaluating predictions on imbalanced examples are required, like ROC area under the curve","title":"Skewed class distribution"},{"location":"ML/Concepts/imbalanced-classification/#cost-sensitivity","text":"It is common for the majority class to represent a normal case in the domain, whereas the minority class to represent an abnormal case (such as a fault, fraud, outlier, anomaly, disease state, ...) As such, the interpretation of misclassification errors may differ across the classes Example: Misclassifying an example for the majority class as an example from the minority class (a so-called false positive) is often not desired, but less critical than classifying an example from the minority class as belonging to the majority class (a so-called false negative) This is referred to as cost sensitivity of misclassification errors","title":"Cost sensitivity"},{"location":"ML/Concepts/imbalanced-classification/#compounding-effects","text":"There are other characteristics of the classification problem that, when combined with these foundational challenges, compound their effect and magnify the difficulty of imbalanced classification problems Dataset size Label noise Data distribution","title":"Compounding effects"},{"location":"ML/Concepts/imbalanced-classification/#effect-of-dataset-size","text":"Dataset size refers to the number of observations collected from the problem domain to fit and evaluate a model Typically, more data is better as it provides more coverage of the domain, perhaps to a point of diminishing returns Specifically, more data provides better representation of combinations and variance of features in the feature space and their mapping to class labels From this, a model can better learn and generalize a class boundary to discriminate new observations in the future If the ratio of examples in the majority class to minority class is somewhat fixed, then we would expect that we would have more examples in the minority class as the size of the dataset is scaled up This is good if we can collect more examples It is a problem typically because data is hard or expensive to collect and we often collect and work with a lot less data than we might prefer As such, this can dramatically impact our ability to gain a large enough or representative sample of examples from the minority class","title":"Effect of dataset size"},{"location":"ML/Concepts/imbalanced-classification/#effect-of-label-noise","text":"","title":"Effect of label noise"},{"location":"ML/Concepts/imbalanced-classification/#effect-of-data-distribution","text":"","title":"Effect of data distribution"},{"location":"ML/Supervised%20Learning/decision-trees/","text":"Decision trees Decision trees allow you to ask multiple linear questions, one after another Can also be used for regression Example Windsurfing: Hey, but hey. x = Wind y = Sun Result: Surfing only when very sunny, and very windy (top right quadrant) UD120 Entropy Measure of impurity in a bunch of examples (basically the opposite of the purity) Controls how a DT decides where to split the data DT try to find subsets that are as pure as possible (lower entropy points) And by repeating this process recursively, that is how a DT classifies events The formula is: \\[ entropy = \\sum_i -p_ilog_2(p_i) \\] Pi is the fraction of examples that are in a given class i Entropy is the sum over all class labels And then, you sum over all the classes that are available Some sources use other bases for the logarithm (for example, they might use log base 10 or the natural log, with a base of approx. 2.72) Those details can change the maximal value of entropy you can get In cases with two classes, the log base 2 formula will have a maximal value of 1 Example All examples are in the same class: entropy = 0 Examples are evenly split between classes: entropy = 1 Example Grade Bumpiness Speed limit Speed steep bumpy yes slow steep smooth yes slow flat bumpy no fast steep smooth no fast What is the entropy of the node \"Speed\": \\(p_{slow}\\) = Fraction of slow examples = Fraction of slow examples 2 slow examples / 4 examples = 0.5 \\(p_{fast}\\) = Fraction of fast examples = Fraction of slow examples 2 slow examples / 4 examples = 0.5 \\(entropy = -\\frac{1}{2} log_2(\\frac{1}{2}) - \\frac{1}{2} log_2(\\frac{1}{2}) = 1\\) import math entropy = - 0.5 * math . log ( 0.5 , 2 ) - 0.5 * math . log ( 0.5 , 2 ) print ( entropy ) 1.0 import scipy.stats entropy = scipy . stats . entropy ([ 1 , 1 ], base = 2 ) print ( entropy ) 1.0 Information gain How does entropy affect how DT draws its boundaries That involves information gain \\[ information gain = entropy(parent) - [weighted average] entropy(children) \\] The DT algorithm will maximize the information gain This is how the DT will choose which feature to make a split on And in cases where the feature has many different values that it can take, this will help the DT figure out where to make that split Example 1: Information gain based on grade graph LR A[SSFF] --> B{Grade} B -->|steep| D[SSF] B -->|flat| E[F] The first node contains 3 examples, the second node only one The entropy of the second node is 0, as all examples belong to the same class \\(entropy_{flat} = -1 log_2(1) - 0 log_2(0)\\) The entropy for the first node can be calculated as follows: The fractions: of examples in each nodes are: \\(p_{slow}\\) = 2/3 \\(p_{fast}\\) = 1/3 \\(entropy_{steep} = -\\frac{2}{3} log_2(\\frac{2}{3}) - \\frac{1}{3} log_2(\\frac{1}{3})\\) import math entropy = - 2 / 3 * math . log ( 2 / 3 , 2 ) - 1 / 3 * math . log ( 1 / 3 , 2 ) print ( entropy ) 0.9182958340544896 import scipy.stats entropy = scipy . stats . entropy ([ 2 , 1 ], base = 2 ) print ( entropy ) 0.9182958340544894 The entropy for the children is the weighted average of the two branches \\(entropy(children) = \\frac{3}{4}(entropy_{steep}) + \\frac{1}{4}(entropy_{flat})\\) 3 / 4 * entropy 0.6887218755408671 The entropy of the parent was one (that is the impure system that you can have with two labels) \\(informationgain = 1 - entropy(children) = 0.3113\\) Example 2: Information gain based on bumpiness graph LR A[SSFF] --> B{Bumpiness} B -->|bumpy| D[SF] B -->|smooth| E[SF] The classes in each node are equally distributed The entropy for both nodes is 1 (the most impure system for two classes) \\(entropy_{bumpy} = -\\frac{1}{2} log_2(\\frac{1}{2}) - \\frac{1}{2} log_2(\\frac{1}{2})\\) \\(entropy_{smooth} = -\\frac{1}{2} log_2(\\frac{1}{2}) - \\frac{1}{2} log_2(\\frac{1}{2})\\) The entropy for the children is 1 \\(entropy(children) = \\frac{1}{2}(entropy_{bumpy}) + \\frac{1}{2}(entropy_{smooth})\\) \\(informationgain = 1 - entropy(children) = 0\\) Example 3: Information gain based on speed limit graph LR A[SSFF] --> B{Speed limit} B -->|yes| D[SS] B -->|no| E[FF] The classes in each node are equally distributed The entropy for both nodes is 0 (the most pure system for two classes) \\(entropy_{yes} = -1 log_2(1) - 1 log_2(1)\\) \\(entropy_{no} = -1 log_2(1) -1 log_2(1)\\) The entropy for the children is 0 \\(entropy(children) = \\frac{1}{2}(entropy_{bumpy}) + \\frac{1}{2}(entropy_{smooth})\\) $ informationgain = 1 - entropy(children) = 1$ Parameters Splitting criterion Entropy Gini: Similar metric of entropy Splitter Maximum depth Minimum number of samples in each split Minimum number of samples in leaf Maximum number of features Minimum density Maximum number of leaf nodes Strengths and weaknesses Strengths Easy to use Graphically (in some sense) and allow you to interpret the data really well, and you can really understand them much better then say the result of a SVM You can build bigger classifiers out of DTs in something called ensemble methods Weaknesses Prone to overfitting Especially if you have data that has a lots and lots of features and a complicated DT can overfit the DT It is important for you to measure how well you're doing, then stop the growth of the tree at the appropriate time References ud120","title":"Lorem ipsum dolor sit amet"},{"location":"ML/Supervised%20Learning/decision-trees/#decision-trees","text":"Decision trees allow you to ask multiple linear questions, one after another Can also be used for regression Example Windsurfing: Hey, but hey. x = Wind y = Sun Result: Surfing only when very sunny, and very windy (top right quadrant) UD120","title":"Decision trees"},{"location":"ML/Supervised%20Learning/decision-trees/#entropy","text":"Measure of impurity in a bunch of examples (basically the opposite of the purity) Controls how a DT decides where to split the data DT try to find subsets that are as pure as possible (lower entropy points) And by repeating this process recursively, that is how a DT classifies events The formula is: \\[ entropy = \\sum_i -p_ilog_2(p_i) \\] Pi is the fraction of examples that are in a given class i Entropy is the sum over all class labels And then, you sum over all the classes that are available Some sources use other bases for the logarithm (for example, they might use log base 10 or the natural log, with a base of approx. 2.72) Those details can change the maximal value of entropy you can get In cases with two classes, the log base 2 formula will have a maximal value of 1 Example All examples are in the same class: entropy = 0 Examples are evenly split between classes: entropy = 1 Example Grade Bumpiness Speed limit Speed steep bumpy yes slow steep smooth yes slow flat bumpy no fast steep smooth no fast What is the entropy of the node \"Speed\": \\(p_{slow}\\) = Fraction of slow examples = Fraction of slow examples 2 slow examples / 4 examples = 0.5 \\(p_{fast}\\) = Fraction of fast examples = Fraction of slow examples 2 slow examples / 4 examples = 0.5 \\(entropy = -\\frac{1}{2} log_2(\\frac{1}{2}) - \\frac{1}{2} log_2(\\frac{1}{2}) = 1\\) import math entropy = - 0.5 * math . log ( 0.5 , 2 ) - 0.5 * math . log ( 0.5 , 2 ) print ( entropy ) 1.0 import scipy.stats entropy = scipy . stats . entropy ([ 1 , 1 ], base = 2 ) print ( entropy ) 1.0","title":"Entropy"},{"location":"ML/Supervised%20Learning/decision-trees/#information-gain","text":"How does entropy affect how DT draws its boundaries That involves information gain \\[ information gain = entropy(parent) - [weighted average] entropy(children) \\] The DT algorithm will maximize the information gain This is how the DT will choose which feature to make a split on And in cases where the feature has many different values that it can take, this will help the DT figure out where to make that split Example 1: Information gain based on grade graph LR A[SSFF] --> B{Grade} B -->|steep| D[SSF] B -->|flat| E[F] The first node contains 3 examples, the second node only one The entropy of the second node is 0, as all examples belong to the same class \\(entropy_{flat} = -1 log_2(1) - 0 log_2(0)\\) The entropy for the first node can be calculated as follows: The fractions: of examples in each nodes are: \\(p_{slow}\\) = 2/3 \\(p_{fast}\\) = 1/3 \\(entropy_{steep} = -\\frac{2}{3} log_2(\\frac{2}{3}) - \\frac{1}{3} log_2(\\frac{1}{3})\\) import math entropy = - 2 / 3 * math . log ( 2 / 3 , 2 ) - 1 / 3 * math . log ( 1 / 3 , 2 ) print ( entropy ) 0.9182958340544896 import scipy.stats entropy = scipy . stats . entropy ([ 2 , 1 ], base = 2 ) print ( entropy ) 0.9182958340544894 The entropy for the children is the weighted average of the two branches \\(entropy(children) = \\frac{3}{4}(entropy_{steep}) + \\frac{1}{4}(entropy_{flat})\\) 3 / 4 * entropy 0.6887218755408671 The entropy of the parent was one (that is the impure system that you can have with two labels) \\(informationgain = 1 - entropy(children) = 0.3113\\) Example 2: Information gain based on bumpiness graph LR A[SSFF] --> B{Bumpiness} B -->|bumpy| D[SF] B -->|smooth| E[SF] The classes in each node are equally distributed The entropy for both nodes is 1 (the most impure system for two classes) \\(entropy_{bumpy} = -\\frac{1}{2} log_2(\\frac{1}{2}) - \\frac{1}{2} log_2(\\frac{1}{2})\\) \\(entropy_{smooth} = -\\frac{1}{2} log_2(\\frac{1}{2}) - \\frac{1}{2} log_2(\\frac{1}{2})\\) The entropy for the children is 1 \\(entropy(children) = \\frac{1}{2}(entropy_{bumpy}) + \\frac{1}{2}(entropy_{smooth})\\) \\(informationgain = 1 - entropy(children) = 0\\) Example 3: Information gain based on speed limit graph LR A[SSFF] --> B{Speed limit} B -->|yes| D[SS] B -->|no| E[FF] The classes in each node are equally distributed The entropy for both nodes is 0 (the most pure system for two classes) \\(entropy_{yes} = -1 log_2(1) - 1 log_2(1)\\) \\(entropy_{no} = -1 log_2(1) -1 log_2(1)\\) The entropy for the children is 0 \\(entropy(children) = \\frac{1}{2}(entropy_{bumpy}) + \\frac{1}{2}(entropy_{smooth})\\) $ informationgain = 1 - entropy(children) = 1$","title":"Information gain"},{"location":"ML/Supervised%20Learning/decision-trees/#parameters","text":"Splitting criterion Entropy Gini: Similar metric of entropy Splitter Maximum depth Minimum number of samples in each split Minimum number of samples in leaf Maximum number of features Minimum density Maximum number of leaf nodes","title":"Parameters"},{"location":"ML/Supervised%20Learning/decision-trees/#strengths-and-weaknesses","text":"","title":"Strengths and weaknesses"},{"location":"ML/Supervised%20Learning/decision-trees/#strengths","text":"Easy to use Graphically (in some sense) and allow you to interpret the data really well, and you can really understand them much better then say the result of a SVM You can build bigger classifiers out of DTs in something called ensemble methods","title":"Strengths"},{"location":"ML/Supervised%20Learning/decision-trees/#weaknesses","text":"Prone to overfitting Especially if you have data that has a lots and lots of features and a complicated DT can overfit the DT It is important for you to measure how well you're doing, then stop the growth of the tree at the appropriate time","title":"Weaknesses"},{"location":"ML/Supervised%20Learning/decision-trees/#references","text":"ud120","title":"References"},{"location":"ML/Unsupervised%20Learning/k-means-clustering/","text":"K-means clustering","title":"K-means clustering"},{"location":"ML/Unsupervised%20Learning/k-means-clustering/#k-means-clustering","text":"","title":"K-means clustering"},{"location":"NLP/catalog/","text":"Natural language processing Processing steps Test 1 Models","title":"Natural language processing"},{"location":"NLP/catalog/#natural-language-processing","text":"","title":"Natural language processing"},{"location":"NLP/catalog/#processing-steps","text":"Test 1","title":"Processing steps"},{"location":"NLP/catalog/#models","text":"","title":"Models"},{"location":"NLP/Modeling/catalog/","text":"Natural language processing Processing steps Test 1 Models","title":"Natural language processing"},{"location":"NLP/Modeling/catalog/#natural-language-processing","text":"","title":"Natural language processing"},{"location":"NLP/Modeling/catalog/#processing-steps","text":"Test 1","title":"Processing steps"},{"location":"NLP/Modeling/catalog/#models","text":"","title":"Models"},{"location":"NLP/Preprocessing/catalog/","text":"Natural language processing Processing steps Test 1 Models","title":"Natural language processing"},{"location":"NLP/Preprocessing/catalog/#natural-language-processing","text":"","title":"Natural language processing"},{"location":"NLP/Preprocessing/catalog/#processing-steps","text":"Test 1","title":"Processing steps"},{"location":"NLP/Preprocessing/catalog/#models","text":"","title":"Models"},{"location":"Stats/","text":"Home Test Commands Test 2 Project layout Test 3","title":"Home"},{"location":"Stats/#home","text":"Test","title":"Home"},{"location":"Stats/#commands","text":"Test 2","title":"Commands"},{"location":"Stats/#project-layout","text":"Test 3","title":"Project layout"},{"location":"Stats/ancova/","text":"ANCOVA Also: Analysis of covariance Objective Control the influence of covariates on the DV Covariates are variables that are not part of the main experimental manipulation but have an influence on the DV Intuition One-way ANOVA can be characterized in terms of multiple regression equations that used dummy variables to code group membership Multiple regression can incorporate several continuous predictor variables Therefore, the regression equation for ANOVA can be extended to include covariates Benefits Reduce within-group error variance If we can explain some of this \"unexplained\" variance (SS R ) using covariates, then we reduce the error variance, allowing us to more accurately assess the effect of the IV (SS M ) Elimination of confounds ANCOVA can remove the bias of variables other than the experimental manipulation that affect the DV Assumptions Independence of the covariate and DV Description In a scenario where the effect of the covariate overlaps with the experimental effect, the covariate will reduce the DV because it explains some of the variance that would otherwise be attributable to the experiment When the covariate and the IV are not independent, the DV is obscured, spurious effects can arise and the interpretation of the ANCOVA is seriously compromised See Field (2012). DSUR for a review of situation in which people misapply ANCOVA Examples Example 1: Compare an anxious group of people against a non-anxious group The chances are that the anxious group would also be more depressed than the non-anxious group Anxiety and depression are closely correlated (anxious people tend to be depressed) and share variance Adding depression as a covariate into the analysis does not help to look on the \"pure\" effect of anxiety The shared variance cannot be separated into \"anxiety variance\" and \"depression variance\" Example 2: Experimental groups that differ in their ages Solutions Randomize participants to experimental group Match experiment groups on the covariate Example: FInd participants for the low anxious group who score high on depression Check Check whether experimental groups differ on the covariate before running the ANVOCA Example: Test whether high and low anxious groups differ on levels of depression (with a t -test or ANOVA) If the groups do not significantly differ then we can use depression as a covariate Homogeneity of regression slopes Effect size Report Reporting ANCOVA is much the same as reporting ANOVA, except we now have to report the effect of the covariate as well Examples Main effects The covariate, {covariate}, was significantly related to {}, F ({}) = {}, p < {}, r = {}. There was also a significant effect of {experimental condition} after controlling for the effect of {covariate}, F ({}) = {}, p < {}, r = {}, partial \u03b72 = {}. Contrasts Planned contrasts revealed that {experimental activity} significantly increased {IV} compared to {experimental activity}, t ({}) = {}, p < {}, r = {}; there was no significant difference between {experimental condition} and {experimental condition}, , t ({}) = {}, p < {}, r = {}. Post hoc tests {name of the post hoc test} post hoc tests revealed that the covariate adjusted mean of the {group name} group was significantly greater than that of the placebo (difference = {},, t = {}, p < {}, d = {}). However, there as no significant different between the {group name} and {group name} groups (difference = {},, t = {}, p < {}, d = {}) and between the {group name} and {group name} groups (difference = {},, t = {}, p < {}, d = {}). Despite the lack of significance between the {group name} and {group name} groups, the effect size was quite large. References Field (2012). DSUR","title":"ANCOVA"},{"location":"Stats/ancova/#ancova","text":"Also: Analysis of covariance","title":"ANCOVA"},{"location":"Stats/ancova/#objective","text":"Control the influence of covariates on the DV Covariates are variables that are not part of the main experimental manipulation but have an influence on the DV","title":"Objective"},{"location":"Stats/ancova/#intuition","text":"One-way ANOVA can be characterized in terms of multiple regression equations that used dummy variables to code group membership Multiple regression can incorporate several continuous predictor variables Therefore, the regression equation for ANOVA can be extended to include covariates","title":"Intuition"},{"location":"Stats/ancova/#benefits","text":"Reduce within-group error variance If we can explain some of this \"unexplained\" variance (SS R ) using covariates, then we reduce the error variance, allowing us to more accurately assess the effect of the IV (SS M ) Elimination of confounds ANCOVA can remove the bias of variables other than the experimental manipulation that affect the DV","title":"Benefits"},{"location":"Stats/ancova/#assumptions","text":"","title":"Assumptions"},{"location":"Stats/ancova/#independence-of-the-covariate-and-dv","text":"","title":"Independence of the covariate and DV"},{"location":"Stats/ancova/#description","text":"In a scenario where the effect of the covariate overlaps with the experimental effect, the covariate will reduce the DV because it explains some of the variance that would otherwise be attributable to the experiment When the covariate and the IV are not independent, the DV is obscured, spurious effects can arise and the interpretation of the ANCOVA is seriously compromised See Field (2012). DSUR for a review of situation in which people misapply ANCOVA","title":"Description"},{"location":"Stats/ancova/#examples","text":"Example 1: Compare an anxious group of people against a non-anxious group The chances are that the anxious group would also be more depressed than the non-anxious group Anxiety and depression are closely correlated (anxious people tend to be depressed) and share variance Adding depression as a covariate into the analysis does not help to look on the \"pure\" effect of anxiety The shared variance cannot be separated into \"anxiety variance\" and \"depression variance\" Example 2: Experimental groups that differ in their ages","title":"Examples"},{"location":"Stats/ancova/#solutions","text":"Randomize participants to experimental group Match experiment groups on the covariate Example: FInd participants for the low anxious group who score high on depression","title":"Solutions"},{"location":"Stats/ancova/#check","text":"Check whether experimental groups differ on the covariate before running the ANVOCA Example: Test whether high and low anxious groups differ on levels of depression (with a t -test or ANOVA) If the groups do not significantly differ then we can use depression as a covariate","title":"Check"},{"location":"Stats/ancova/#homogeneity-of-regression-slopes","text":"","title":"Homogeneity of regression slopes"},{"location":"Stats/ancova/#effect-size","text":"","title":"Effect size"},{"location":"Stats/ancova/#report","text":"Reporting ANCOVA is much the same as reporting ANOVA, except we now have to report the effect of the covariate as well","title":"Report"},{"location":"Stats/ancova/#examples_1","text":"","title":"Examples"},{"location":"Stats/ancova/#main-effects","text":"The covariate, {covariate}, was significantly related to {}, F ({}) = {}, p < {}, r = {}. There was also a significant effect of {experimental condition} after controlling for the effect of {covariate}, F ({}) = {}, p < {}, r = {}, partial \u03b72 = {}.","title":"Main effects"},{"location":"Stats/ancova/#contrasts","text":"Planned contrasts revealed that {experimental activity} significantly increased {IV} compared to {experimental activity}, t ({}) = {}, p < {}, r = {}; there was no significant difference between {experimental condition} and {experimental condition}, , t ({}) = {}, p < {}, r = {}.","title":"Contrasts"},{"location":"Stats/ancova/#post-hoc-tests","text":"{name of the post hoc test} post hoc tests revealed that the covariate adjusted mean of the {group name} group was significantly greater than that of the placebo (difference = {},, t = {}, p < {}, d = {}). However, there as no significant different between the {group name} and {group name} groups (difference = {},, t = {}, p < {}, d = {}) and between the {group name} and {group name} groups (difference = {},, t = {}, p < {}, d = {}). Despite the lack of significance between the {group name} and {group name} groups, the effect size was quite large.","title":"Post hoc tests"},{"location":"Stats/ancova/#references","text":"Field (2012). DSUR","title":"References"},{"location":"Stats/confounds/","text":"Confounds In any experiment, there may be unmeasured variables that confound the results","title":"Confounds"},{"location":"Stats/confounds/#confounds","text":"In any experiment, there may be unmeasured variables that confound the results","title":"Confounds"},{"location":"Stats/within-group-error-variance/","text":"Within-group error variance The amount of variability in the data that the experiment cannot explain Related to: ANOVA t -test References Field (2012). DSUR","title":"Within-group error variance"},{"location":"Stats/within-group-error-variance/#within-group-error-variance","text":"The amount of variability in the data that the experiment cannot explain Related to: ANOVA t -test","title":"Within-group error variance"},{"location":"Stats/within-group-error-variance/#references","text":"Field (2012). DSUR","title":"References"},{"location":"Stats/Modeling/catalog/","text":"Natural language processing Processing steps Test 1 Models","title":"Natural language processing"},{"location":"Stats/Modeling/catalog/#natural-language-processing","text":"","title":"Natural language processing"},{"location":"Stats/Modeling/catalog/#processing-steps","text":"Test 1","title":"Processing steps"},{"location":"Stats/Modeling/catalog/#models","text":"","title":"Models"}]}; var __search = { index: Promise.resolve(local_index) }